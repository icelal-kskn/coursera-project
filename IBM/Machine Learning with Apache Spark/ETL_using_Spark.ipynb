{"cells":[{"cell_type":"markdown","id":"7f5f641d-687d-4402-ba02-d9d3a795d6e0","metadata":{},"outputs":[],"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"f4cbc69f-1910-4c89-b620-e63041e8a19f","metadata":{},"outputs":[],"source":["## ETL using Spark\n"]},{"cell_type":"markdown","id":"c9517851-49ac-49d3-9a8f-926b43db7bd4","metadata":{},"outputs":[],"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","id":"97d244b2-615e-4be7-9938-6087a088164f","metadata":{},"outputs":[],"source":["\u003cp style='color: red'\u003eThe purpose of this lab is to show you how to use Spark for ETL jobs.\n"]},{"cell_type":"markdown","id":"2bc1c8fd-737b-4dc5-82eb-268dc51d6f9e","metadata":{},"outputs":[],"source":["## __Table of Contents__\n","\n","\u003col\u003e\n","  \u003cli\u003e\n","    \u003ca href=\"#Objectives\"\u003eObjectives\n","    \u003c/a\u003e\n","  \u003c/li\u003e\n","  \u003cli\u003e\n","    \u003ca href=\"#Datasets\"\u003eDatasets\n","    \u003c/a\u003e\n","  \u003c/li\u003e\n","  \u003cli\u003e\n","    \u003ca href=\"#Setup\"\u003eSetup\n","    \u003c/a\u003e\n","    \u003col\u003e\n","      \u003cli\u003e\n","        \u003ca href=\"#Installing-Required-Libraries\"\u003eInstalling Required Libraries\n","        \u003c/a\u003e\n","      \u003c/li\u003e\n","      \u003cli\u003e\n","        \u003ca href=\"#Importing-Required-Libraries\"\u003eImporting Required Libraries\n","        \u003c/a\u003e\n","      \u003c/li\u003e\n","    \u003c/ol\u003e\n","  \u003c/li\u003e\n","  \u003cli\u003e \n","    \u003ca href=\"#Examples\"\u003eExamples\n","    \u003c/a\u003e\n","    \u003col\u003e\n","    \u003cli\u003e\n","      \u003ca href=\"#Task-1---Create-a-Dataframe-from-the-raw-data-and-write-to-CSV-file.\"\u003eTask 1 - Create a Dataframe from the raw data and write to CSV file.\n","      \u003c/a\u003e\n","    \u003c/li\u003e\n","    \u003cli\u003e\n","      \u003ca href=\"#Task-2---Read-from-a-csv-file-and-write-to-parquet-file\"\u003eTask 2 - Read from a csv file and write to parquet file\n","      \u003c/a\u003e\n","    \u003c/li\u003e\n","    \u003cli\u003e\n","      \u003ca href=\"#Task-3---Condense-PARQUET-to-a-single-file.\"\u003eTask 3 - Condense PARQUET to a single file.\n","      \u003c/a\u003e\n","    \u003c/li\u003e\n","    \u003cli\u003e\n","      \u003ca href=\"#Task-4---Read-from-a-parquet-file-and-write-to-csv-file\"\u003eTask 4 - Read from a parquet file and write to csv file\n","      \u003c/a\u003e\n","    \u003c/li\u003e\n","      \u003c/ol\u003e\n","  \u003cli\u003e\n","    \u003ca href=\"#Exercises\"\u003eExercises\n","    \u003c/a\u003e\n","  \u003c/li\u003e\n","  \u003col\u003e\n","    \u003cli\u003e\n","      \u003ca href=\"#Exercise-1---Extract\"\u003eExercise 1 - Extract\n","      \u003c/a\u003e\n","    \u003c/li\u003e\n","    \u003cli\u003e\n","      \u003ca href=\"#Exercise-2---Transform\"\u003eExercise 2 - Transform\n","      \u003c/a\u003e\n","    \u003c/li\u003e\n","    \u003cli\u003e\n","      \u003ca href=\"#Exercise-3---Load\"\u003eExercise 3 - Load\n","      \u003c/a\u003e\n","    \u003c/li\u003e\n","  \u003c/ol\u003e\n","\u003c/ol\u003e\n"]},{"cell_type":"markdown","id":"98d6152f-2c84-4ce1-b500-23a45b2cf1aa","metadata":{},"outputs":[],"source":["## Objectives\n","\n","After completing this lab you will be able to:\n"," \n"," - Create a Spark Dataframe from the raw data and write to CSV file.\n"," - Read from a csv file and write to parquet file\n"," - Condense PARQUET to a single file.\n"," - Read from a parquet file and write to csv file\n"]},{"cell_type":"markdown","id":"17301cef-72f8-435f-8b7e-7982b005ad0d","metadata":{},"outputs":[],"source":["----\n"]},{"cell_type":"markdown","id":"0f29008e-9ac8-469d-a7a3-8e940693aebc","metadata":{},"outputs":[],"source":["## Setup\n"]},{"cell_type":"markdown","id":"f08881f6-ce16-4b04-9189-16b3d65fd972","metadata":{},"outputs":[],"source":["For this lab, we will be using the following libraries:\n","\n","*   [`PySpark`](https://spark.apache.org/docs/latest/api/python/index.html?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01) for connecting to the Spark Cluster\n"]},{"cell_type":"markdown","id":"ae3392ce-86ee-4e1c-815b-eceb9a0ba2e2","metadata":{},"outputs":[],"source":["### Installing Required Libraries\n","\n","Spark Cluster is pre-installed in the Skills Network Labs environment. However, you need libraries like pyspark and findspark to connect to this cluster.\n","\n","If you wish to download this jupyter notebook and run on your local computer, follow the instructions mentioned \u003ca href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/labs/Connecting_to_spark_cluster_using_Skills_Network_labs.ipynb\"\u003ehere.\u003c/a\u003e\n","\n"]},{"cell_type":"markdown","id":"d42b5da8-ae08-46d8-ba9f-335af7976ebf","metadata":{},"outputs":[],"source":["The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"]},{"cell_type":"code","id":"349a5914-b74e-4b77-bedf-a19cf58ecf31","metadata":{},"outputs":[],"source":["!pip install pyspark==3.1.2 -q\n!pip install findspark -q"]},{"cell_type":"markdown","id":"7622a460-3386-422a-983e-31bf92949581","metadata":{},"outputs":[],"source":["### Importing Required Libraries\n","\n","_We recommend you import all required libraries in one place (here):_\n"]},{"cell_type":"code","id":"108b2afc-c177-4a23-876d-21a3f1f0683d","metadata":{},"outputs":[],"source":["# You can also use this section to suppress warnings generated by your code:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\nwarnings.filterwarnings('ignore')\n\n# FindSpark simplifies the process of using Apache Spark with Python\n\nimport findspark\nfindspark.init()\n\nfrom pyspark.sql import SparkSession\n"]},{"cell_type":"code","id":"29d531aa-6bda-4047-b83d-c6f7989ebbb3","metadata":{},"outputs":[],"source":["#Create SparkSession\n#Ignore any warnings by SparkSession command\n\nspark = SparkSession.builder.appName(\"ETL using Spark\").getOrCreate()"]},{"cell_type":"markdown","id":"7cfe1c80-ff6f-4b6c-9fad-f78b8acdf643","metadata":{},"outputs":[],"source":["## Task 1 - Create a Dataframe from the raw data and write to CSV file.\n"]},{"cell_type":"code","id":"0c090e67-d3a7-4eca-bfc0-1a83c2020793","metadata":{},"outputs":[],"source":["#create a list of tuples\n#each tuple contains the student id, height and weight\ndata = [(\"student1\",64,90),\n        (\"student2\",59,100),\n        (\"student3\",69,95),\n        (\"\",70,110),\n        (\"student5\",60,80),\n        (\"student3\",69,95),\n        (\"student6\",62,85),\n        (\"student7\",65,80),\n        (\"student7\",65,80)]\n\n# some rows are intentionally duplicated"]},{"cell_type":"code","id":"e4c96859-55b0-4c1b-b1c6-5d9216e7f787","metadata":{},"outputs":[],"source":["#create a dataframe using createDataFrame and pass the data and the column names.\n\ndf = spark.createDataFrame(data, [\"student\",\"height_inches\",\"weight_pounds\"])"]},{"cell_type":"code","id":"488bfabd-88af-4d97-a8ff-ffeed61bca00","metadata":{},"outputs":[],"source":["# show the data frame\n\ndf.show()"]},{"cell_type":"markdown","id":"630fd651-4ceb-4da8-ba1d-33acce3d56c0","metadata":{},"outputs":[],"source":["Write to csv file\n"]},{"cell_type":"code","id":"a016d655-5679-40a5-8d2b-3b08e15d6e74","metadata":{},"outputs":[],"source":["df.write.mode(\"overwrite\").csv(\"student-hw.csv\", header=True)"]},{"cell_type":"code","id":"51ea60dc-aaa8-4b21-8f80-6bd86e39ef91","metadata":{},"outputs":[],"source":["#If you do not wish to over write use df.write.csv(\"student-hw.csv\", header=True)"]},{"cell_type":"markdown","id":"a706a34e-44f1-4040-9cf4-22e5916ace71","metadata":{},"outputs":[],"source":["Verify the csv file\n"]},{"cell_type":"code","id":"1d4e55d9-f94b-430b-aee6-581b65bfbeb2","metadata":{},"outputs":[],"source":["# Load student dataset\ndf = spark.read.csv(\"student-hw.csv\", header=True, inferSchema=True)\n\n# display dataframe\ndf.show()"]},{"cell_type":"markdown","id":"b51cff1b-a7e8-4d96-9d36-5513d70cc8bd","metadata":{},"outputs":[],"source":["## Task 2 - Read from a csv file and write to parquet file\n"]},{"cell_type":"code","id":"b36342a7-4919-42c7-b6cc-c628d0236c9e","metadata":{},"outputs":[],"source":["# Load student dataset\ndf = spark.read.csv(\"student-hw.csv\", header=True, inferSchema=True)\n\n# display dataframe\ndf.show()"]},{"cell_type":"code","id":"edcfaeef-0a23-4168-ac91-8a2d087661fd","metadata":{},"outputs":[],"source":["# print the number of rows in the dataframe\ndf.count()"]},{"cell_type":"markdown","id":"4ee64e03-988b-48a0-b189-41fa0cb4ad80","metadata":{},"outputs":[],"source":["Drop Duplicates\n"]},{"cell_type":"code","id":"ad2c9889-bff4-46ab-aa3d-743d2b1cb2c3","metadata":{},"outputs":[],"source":["df = df.dropDuplicates()"]},{"cell_type":"code","id":"c15699e7-74c9-4050-80ab-544038b95254","metadata":{},"outputs":[],"source":["df.show()"]},{"cell_type":"code","id":"4f7a845f-ef87-479b-8279-5bfb19de9bef","metadata":{},"outputs":[],"source":["#Notice that the duplicates are removed"]},{"cell_type":"code","id":"28778131-3b44-428e-a95d-3c1d64dfec22","metadata":{},"outputs":[],"source":["# print the number of rows in the dataframe\ndf.count()"]},{"cell_type":"markdown","id":"f6a6319f-a8f3-4c97-bb4c-155acae0597b","metadata":{},"outputs":[],"source":["Drop Null values\n"]},{"cell_type":"code","id":"5569860e-a582-43d7-88a9-cd9e34c3da4c","metadata":{},"outputs":[],"source":["df=df.dropna()"]},{"cell_type":"code","id":"52343b42-33e1-410a-ba03-f49924d74cc6","metadata":{},"outputs":[],"source":["#Observe the rows with null values getting dropped\ndf.show()"]},{"cell_type":"markdown","id":"b19f252a-503b-4257-a9f9-cba1a724d222","metadata":{},"outputs":[],"source":["Save to parquet file\n"]},{"cell_type":"code","id":"ca94d941-8962-46e3-a184-7e4a1f04aba4","metadata":{},"outputs":[],"source":["#Write the data to a Parquet file\ndf.write.mode(\"overwrite\").parquet(\"student-hw.parquet\")"]},{"cell_type":"code","id":"479aec2c-d388-42cd-8cdf-d4b2863ae99f","metadata":{},"outputs":[],"source":["# if you do not wish to overwrite use the command df.write.parquet(\"student-hw.parquet\")"]},{"cell_type":"code","id":"07977aae-0c18-4ab9-a38d-4430cb6c18f9","metadata":{},"outputs":[],"source":["# verify that the parquet file(s) are created"]},{"cell_type":"code","id":"54733ff3-e25f-4079-a355-846d5a228f2d","metadata":{},"outputs":[],"source":["!!ls -l student-hw.parquet"]},{"cell_type":"markdown","id":"fa4c5c02-db13-4b1e-93d1-07ea0c649d18","metadata":{},"outputs":[],"source":["Notice that there are a lot of .parquet files in the output.\n","- To improve parallellism, spark stores each dataframe in multiple partitions.\n","- When the data is saved as parquet file, each partition is saved as a separate file.\n"]},{"cell_type":"markdown","id":"ac7b75bf-36b0-483c-9a7d-aca64818d8da","metadata":{},"outputs":[],"source":["## Task 3 - Condense PARQUET to a single file.\n"]},{"cell_type":"markdown","id":"6bb2aa1c-cdb7-49df-b1d4-c4d8eb85d573","metadata":{},"outputs":[],"source":["Reduce the number of partitions in the dataframe to one.\n"]},{"cell_type":"code","id":"5763418b-88be-4cff-8728-ab6378803616","metadata":{},"outputs":[],"source":["df = df.repartition(1)"]},{"cell_type":"markdown","id":"af4c05d0-41e4-4932-8dc7-6cb303632aa2","metadata":{},"outputs":[],"source":["Save to parquet file\n"]},{"cell_type":"code","id":"3aaef83b-b9c4-44dc-9ecf-995961cdd104","metadata":{},"outputs":[],"source":["#Write the data to a Parquet file\ndf.write.mode(\"overwrite\").parquet(\"student-hw-single.parquet\")"]},{"cell_type":"code","id":"6f2c90de-57c3-4f66-8ddb-a0d9d4e437db","metadata":{},"outputs":[],"source":["# if you do not wish to overwrite use the command df.write.parquet(\"student-hw-single.parquet\")"]},{"cell_type":"code","id":"efe94886-dc5f-4c0b-9175-bea7247b3094","metadata":{},"outputs":[],"source":["# verify that the parquet file(s) are created"]},{"cell_type":"code","id":"3b296a3d-dfb2-492c-8c1a-df66af798874","metadata":{},"outputs":[],"source":["!ls -l student-hw-single.parquet"]},{"cell_type":"code","id":"9216fb54-3b1f-4c5d-bc23-1d8f8b264ba5","metadata":{},"outputs":[],"source":["#Notice that there is only one .parquet file"]},{"cell_type":"markdown","id":"862b5d56-56a5-4199-a242-fbd31bfc26e8","metadata":{},"outputs":[],"source":["## Task 4 - Read from a parquet file and write to csv file\n"]},{"cell_type":"code","id":"6dce06c6-628e-43d7-b53c-57081e5232db","metadata":{},"outputs":[],"source":["df = spark.read.parquet(\"student-hw-single.parquet\")"]},{"cell_type":"code","id":"7c55a891-7426-43cf-b7c0-9dafc4f0f52d","metadata":{},"outputs":[],"source":["df.show()"]},{"cell_type":"markdown","id":"2588a5c7-9d45-4a1c-8aed-b1258c2e98fb","metadata":{},"outputs":[],"source":["Transform the data\n"]},{"cell_type":"code","id":"6171f469-84ee-4125-8e7e-ef48a09de4a4","metadata":{},"outputs":[],"source":["#import the expr function that helps in transforming the data\nfrom pyspark.sql.functions import expr"]},{"cell_type":"markdown","id":"0cb8953c-b31f-447b-ae73-788ce886fca6","metadata":{},"outputs":[],"source":["Convert inches to centimeters\n"]},{"cell_type":"code","id":"0e026334-513d-4a1c-9721-0c552fd74acd","metadata":{},"outputs":[],"source":["# Convert inches to centimeters\n# Multiply the column height_inches with 2.54 to get a new column height_centimeters\ndf = df.withColumn(\"height_centimeters\", expr(\"height_inches * 2.54\"))\ndf.show()"]},{"cell_type":"markdown","id":"32cbba91-78b0-465b-a30d-4f1b58c33dc8","metadata":{},"outputs":[],"source":["Convert pounds to kilograms\n"]},{"cell_type":"code","id":"8289629f-eff6-40c8-a2c9-0d3aa6f1fc23","metadata":{},"outputs":[],"source":["# Convert pounds to kilograms\n# Multiply weight_pounds with 0.453592 to get a new column weight_kg\ndf = df.withColumn(\"weight_kg\", expr(\"weight_pounds * 0.453592\"))\ndf.show()"]},{"cell_type":"markdown","id":"14687a06-793f-4bc8-ac76-58b9653dbb01","metadata":{},"outputs":[],"source":["Drop the columns\n"]},{"cell_type":"code","id":"caf7523d-0d8f-42d1-a1ce-242cc9347580","metadata":{},"outputs":[],"source":["# drop the columns \"height_inches\",\"weight_pounds\"\ndf = df.drop(\"height_inches\",\"weight_pounds\")\ndf.show()"]},{"cell_type":"markdown","id":"b7d79e20-2e04-422f-9bbb-cdd7d34dbbe0","metadata":{},"outputs":[],"source":["Rename a column\n"]},{"cell_type":"code","id":"57cdb2fe-7ce4-4c28-9690-02911f3dc5fe","metadata":{},"outputs":[],"source":["# rename the lengthy column name \"height_centimeters\" to \"height_cm\"\ndf = df.withColumnRenamed(\"height_centimeters\",\"height_cm\")\ndf.show()"]},{"cell_type":"markdown","id":"44ecb95c-d0ce-4da8-ba79-847e44135218","metadata":{},"outputs":[],"source":["Save to csv file\n"]},{"cell_type":"code","id":"052deb0e-cd0c-41e2-bb42-33ad558490fb","metadata":{},"outputs":[],"source":["df.write.mode(\"overwrite\").csv(\"student_transformed.csv\", header=True)"]},{"cell_type":"markdown","id":"9b098382-0e60-4faa-9798-baa3904afd55","metadata":{},"outputs":[],"source":["Verify the csv file\n"]},{"cell_type":"code","id":"abe26eea-7292-495b-9e08-9b72be17ea78","metadata":{},"outputs":[],"source":["# Load student dataset\ndf = spark.read.csv(\"student_transformed.csv\", header=True, inferSchema=True)\n# display dataframe\ndf.show()"]},{"cell_type":"markdown","id":"ab128f8f-e332-449c-bb00-213a0693cab1","metadata":{},"outputs":[],"source":["Stop Spark Session\n"]},{"cell_type":"code","id":"f71d336c-a18a-4981-819c-f03f54f10504","metadata":{},"outputs":[],"source":["spark.stop()"]},{"cell_type":"markdown","id":"581c22d3-773f-483b-87a5-ca2e7df2e0a0","metadata":{},"outputs":[],"source":["# Exercises\n"]},{"cell_type":"markdown","id":"67229f40-99f3-4cc4-a270-faa1d90513fa","metadata":{},"outputs":[],"source":["Create Spark Session\n"]},{"cell_type":"code","id":"ebcaee60-925e-442e-98fd-e8abeaa04b2b","metadata":{},"outputs":[],"source":["#Create SparkSession\n#Ignore any warnings by SparkSession command\n\nspark = SparkSession.builder.appName(\"Exercises - ETL using Spark\").getOrCreate()"]},{"cell_type":"markdown","id":"7481eebb-942f-4c69-a2a0-42060aee658a","metadata":{},"outputs":[],"source":["### Exercise 1 - Extract\n"]},{"cell_type":"markdown","id":"56e43465-2008-4d1e-8981-e3daff0b31ad","metadata":{},"outputs":[],"source":["Load data from student_transformed.csv into a dataframe\n"]},{"cell_type":"code","id":"83922c60-a096-45bf-8ecb-4b75d2346103","metadata":{},"outputs":[],"source":["# Load student dataset\ndf = #TODO\n# display dataframe\n#TODO"]},{"cell_type":"markdown","id":"e4be8ed8-1702-473e-89ed-47df9a5ef21c","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for a Hint\u003c/summary\u003e\n","    \n","Use spark.read.csv\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"e34cfc4d-057e-4094-a4db-189e2e465b1d","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for Solution\u003c/summary\u003e\n","\n","```\n","# Load student dataset\n","df = spark.read.csv(\"student_transformed.csv\", header=True, inferSchema=True)\n","# display dataframe\n","df.show()\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"8bfb7e02-e31f-41b1-ac78-1b1ecdaa978e","metadata":{},"outputs":[],"source":["### Exercise 2 - Transform\n"]},{"cell_type":"markdown","id":"b4c4b6b4-167d-4cbc-a9f8-f46c6e7a6bcb","metadata":{},"outputs":[],"source":["Convert cm to meters\n"]},{"cell_type":"code","id":"2d110447-f7e5-4889-b8d2-56ab642d26c2","metadata":{},"outputs":[],"source":["#import the expr function that helps in transforming the data\n"]},{"cell_type":"code","id":"3be7ea67-8360-4094-ae93-5eb7cf6184e0","metadata":{},"outputs":[],"source":["# Convert centimeters to meters\n# Divide the column height_cm by 100 a new column height_cm\ndf = #TODO\n# display dataframe\n#TODO"]},{"cell_type":"markdown","id":"ee9d4ca5-d119-489f-8e1c-79f95c987f17","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for a Hint\u003c/summary\u003e\n","    \n","Use df.withColumn() method\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"90a4de1c-d47b-47ab-8245-a582bb20e2cb","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for Solution\u003c/summary\u003e\n","\n","```\n","# Divide the column height_cm by 100 a new column height_cm\n","df = df.withColumn(\"height_meters\", expr(\"height_cm / 100\"))\n","# display dataframe\n","df.show()\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"6b49dc49-8246-42cd-945f-63ee80032541","metadata":{},"outputs":[],"source":["Create a column named bmi\n"]},{"cell_type":"code","id":"293188bb-d1bf-4a42-87d3-5dbeed830d87","metadata":{},"outputs":[],"source":["# compute bmi using the below formula\n# BMI = weight/(height * height)\n# weight must be in kgs\n# height must be in meters\ndf = #TODO\n# display dataframe\n#TODO"]},{"cell_type":"markdown","id":"01c9c41b-7b01-45dc-b082-3ced03f35d68","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for a Hint\u003c/summary\u003e\n","    \n","Use df.withColumn() method\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"a9cc4499-b04b-45ab-ae9c-32d1a7324574","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for Solution\u003c/summary\u003e\n","\n","```\n","df = df.withColumn(\"bmi\", expr(\"weight_kg/(height_meters*height_meters)\"))\n","# display dataframe\n","df.show()\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"7ca3bc92-4382-41a8-962a-caf49f0e51ae","metadata":{},"outputs":[],"source":["Drop the columns height_inches, weight_pounds\n"]},{"cell_type":"code","id":"db378a57-5d79-414b-9114-25508402e253","metadata":{},"outputs":[],"source":["# drop the columns \"height_inches\",\"weight_pounds\"\ndf = #TODO\n# display dataframe\n#TODO"]},{"cell_type":"markdown","id":"d4457555-af6c-4f1e-80d5-2656958f409e","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for a Hint\u003c/summary\u003e\n","    \n","Use df.drop()\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"428e443e-f16a-4af6-ad6e-98e61c2d21c5","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for Solution\u003c/summary\u003e\n","\n","```\n","# drop the columns \"height_inches\",\"weight_pounds\"\n","df = df.drop(\"height_cm\",\"weight_kg\",\"height_meters\")\n","# display dataframe\n","df.show()\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"code","id":"f1bedfd3-3560-474e-9215-0673b2015533","metadata":{},"outputs":[],"source":["# Let us round the column bmi"]},{"cell_type":"code","id":"2d966d23-8478-4b64-8779-3f95e0c309c9","metadata":{},"outputs":[],"source":["from pyspark.sql.functions import col, round\ndf = df.withColumn(\"bmi_rounded\", round(col(\"bmi\")))\ndf.show()"]},{"cell_type":"markdown","id":"ae030f33-4b13-4737-affa-905ba7fe15d9","metadata":{},"outputs":[],"source":["### Exercise 3 - Load\n"]},{"cell_type":"markdown","id":"bb0f8524-3ccf-4178-b745-99874545564d","metadata":{},"outputs":[],"source":["Save the dataframe into a parquet file\n"]},{"cell_type":"code","id":"37930271-ed59-4fdd-899b-5f38bf0b937c","metadata":{},"outputs":[],"source":["#Write the data to a Parquet file, set the mode to overwrite\n#TODO"]},{"cell_type":"markdown","id":"b18185db-b0d1-4cef-a5d2-6c26eaf0821a","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for a Hint\u003c/summary\u003e\n","    \n","Use df.write\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"4f564445-4166-4e1a-a9d7-8a0c3c1de33b","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for Solution\u003c/summary\u003e\n","\n","```\n","df.write.mode(\"overwrite\").parquet(\"student_transformed.parquet\")\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"15593e59-8f12-49c8-984e-b119d668aae8","metadata":{},"outputs":[],"source":["Stop Spark Session\n"]},{"cell_type":"code","id":"4531c9ac-49d1-422e-9c0b-a23b38b05b18","metadata":{},"outputs":[],"source":["spark.stop()"]},{"cell_type":"markdown","id":"00c44c9e-e56a-4545-b9f5-e393e92d4fb5","metadata":{},"outputs":[],"source":["Congratulations you have completed this lab.\u003cbr\u003e\n"]},{"cell_type":"markdown","id":"edb581a4-4712-4edf-889e-66f076e07f87","metadata":{},"outputs":[],"source":["## Authors\n"]},{"cell_type":"markdown","id":"9f5ba319-1c68-4d8e-bfa2-60cae88afe60","metadata":{},"outputs":[],"source":["[Ramesh Sannareddy](https://www.linkedin.com/in/rsannareddy/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMBD0231ENSkillsNetwork866-2023-01-01)\n"]},{"cell_type":"markdown","id":"8709b91c-d2bf-4df8-a4ec-28e60f2d97d9","metadata":{},"outputs":[],"source":["### Other Contributors\n"]},{"cell_type":"markdown","id":"4bee46f6-d2a2-4941-9ffc-51db15b767ed","metadata":{},"outputs":[],"source":["## Change Log\n"]},{"cell_type":"markdown","id":"7bbf3b41-1a1d-42e8-92bf-6bb1c8c2e097","metadata":{},"outputs":[],"source":["|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n","|-|-|-|-|\n","|2023-05-21|0.1|Ramesh Sannareddy|Initial Version Created|\n"]},{"cell_type":"markdown","id":"0099d329-d2c2-4a31-8838-e51315c42d90","metadata":{},"outputs":[],"source":["Copyright Â© 2023 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}